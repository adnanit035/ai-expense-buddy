{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TogetherAI Allow free Use of 11B Llama VLM but it does allow us to set instruction\n",
    "\n",
    "\n",
    "1) Since the usage of ***Llama 11 B*** is freely available from ***Together AI*** i wanted to tes how it performs. The results are satisfactory and consistant only problem is that It can be finetuned further and also it can not take instructions such as provide us result in ***JSON etc***. for that another model such as ***Llama 11b Instruct*** is awesome but we need to think about hosting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'base64' from 'c:\\\\Users\\\\Utente\\\\miniconda3\\\\envs\\\\OCR_tests\\\\Lib\\\\base64.py'>\n",
      "**Invoice Details**\n",
      "\n",
      "*   **Description**: Kaleem Ullah 2\n",
      "*   **Price**: 684,00\n",
      "*   **VAT**: 22,00%\n",
      "*   **Date**: 11-10-2024 13:01\n",
      "*   **Seller**: Defanti's Club S.r.l."
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "import base64\n",
    "\n",
    "\n",
    "client = Together(api_key = '****')\n",
    "\n",
    "\n",
    "image_path = r\"C:\\Users\\Utente\\Projects\\ai-expense-buddy\\data\\yep.jpg\"  \n",
    "\n",
    "def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "print(base64)       \n",
    "\n",
    "query = \"\"\"\n",
    "        provide me DESCRIZIONE with PREZZO and IVA, DATA and Seller.\n",
    "    \"\"\"\n",
    "messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    "    messages=messages,\n",
    "    max_tokens=None,\n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "\n",
    "text = ''\n",
    "for chunk in response:\n",
    "    if len(chunk.choices) != 0:\n",
    "        print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)\n",
    "        text += chunk.choices[0].delta.content + ' '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaddleOCR\n",
    "\n",
    "1) Another Method that I think could work is that we extract the text manually with the help of best OCR Extraction tool out there in this case I found PaddleOCR which works like charm. So I plan to use this to extract the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/11/18 22:37:39] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Utente/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Utente/.paddleocr/whl\\\\rec\\\\latin\\\\latin_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\Utente\\\\miniconda3\\\\envs\\\\OCR_tests\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\latin_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\Utente/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='it', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/11/18 22:37:41] ppocr DEBUG: dt_boxes num : 83, elapsed : 0.3166389465332031\n",
      "[2024/11/18 22:37:42] ppocr DEBUG: cls num  : 83, elapsed : 0.5398786067962646\n",
      "[2024/11/18 22:37:45] ppocr DEBUG: rec_res num  : 83, elapsed : 3.2851388454437256\n",
      " MIT MD SpA a Socio Unico PARTITA.TVA03185210618 Via di Madonna Bianca Trento-38123TN) NON FISCALE DOCUMENTO COMMERCIALE IVA% PREZZO PER COMPOSTABILE BIO MD EURO 33-80 0 4,00 CONI DI MAIS 4,00 10,00 10,00 Subtot 6,51 TOTALE di cui IVA Pagamento elettronico RESTO IMPORTO PAGATO 6,51 03-11-202415.25 Documento N.1940-0100 Matricola Server RT:99SEA004099 Matricola Cassa:38450002 Codice CCDC: 1103T15252538450002194001006fbed123a10ad63 e5b33015f661f5cd2bb0a4c7342486510bef7e0e DETTAGLIO FORME DI PAGAMENTO JMAT *********************** 6,51 RAPPORTO EFT-POS UcMastercard MCCLess ACQUISTO VIA DI STELLA DI MAN SPA TRENTO Eserc A.I.I.C 310753100305 Data 03/11/24.-0ra15:25 00000000070 TML pow Online AUT. AUTH.RESP. H20487 PAN OPERO SCAD *******752 A.ID A0000000041010 APPL MASTERCARD ATC 039A TrCC 978 UNB8FO0611 FVR 0000008001 ARQC 2257AD52FFB78548 00000000000000FF CVM No CVM IMPORTO EUR TRANSAZIONE ESEGUITA 6,51 GRAZIE.E ARRIVEDERCI UNICREDIT SPA RAPPORTO EFTPOS \n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Paddleocr supports Chinese, English, French, German, Korean and Japanese\n",
    "# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n",
    "# to switch the language model in order\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='it') # need to run only once to download and load model into memory\n",
    "img_path = r\"C:\\Users\\Utente\\Projects\\ai-expense-buddy\\data\\WhatsApp Image 2024-11-03 at 17.07.02.jpeg\"\n",
    "result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "text = ' '\n",
    "for idx in range(len(result)):\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        #print(line)\n",
    "        text += line[1][0] + ' '\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_11952\\3466856374.py:25: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings      \n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,  pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking\")\n",
    "\n",
    "# Load the LLM pipeline\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0,\n",
    "    max_length=3000,  # Increase max_length as per your input size\n",
    "    max_new_tokens=1000  # Control the output length\n",
    ")\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "documents = [\n",
    "    text\n",
    "]\n",
    "\n",
    "# Create the FAISS index with embeddings\n",
    "vector_store = FAISS.from_texts(documents, embedding_model)\n",
    "\n",
    "# Step 3: Set up the retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an helpful and friendly assistant for question-answering tasks. \"\n",
    "    \"The text you will be seeing is extracted from italian invoice\"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, Just say 'Text Doesnt Mention it'\"\n",
    "    \"Answer in very pricise manner\"\n",
    "    \"You need to provide me the following details in json format VenderName , TotalPrice , Dataofpurchase , Each Item withs price\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Both `max_new_tokens` (=1000) and `max_length`(=3000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": 'Extract me the useful information'})['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- VenderName: MIT MD SpA\n",
      "- TotalPrice: €33.80\n",
      "- Dataofpurchase: 03/11/24\n",
      "- Each Item withs price:\n",
      "  - Coni di Mais: €4.00\n",
      "  - Bio: €10.00\n",
      "  - Subtot: €6.51\n",
      "  - Totale di cui IVA: €6.51\n",
      "  - Importo Pago: €6.51\n",
      "  - Data: 03/11/24\n",
      "  - Tipo di pagamento: EFT-POS\n",
      "  - Forma di pagamento: UcMastercard\n",
      "  - ID: A.ID\n",
      "  - CVM: No CVM\n",
      "  - CVM: No CVM\n",
      "  - Tipo di pagamento: No CVM\n",
      "  - Tipo di pagamento: No CVM\n",
      "  - Tipo di pagamento: No CVM\n",
      "\n",
      "The final answer is: \n",
      "```\n",
      "{\n",
      "  \"VenderName\": \"MIT MD SpA\",\n",
      "  \"TotalPrice\": \"€33.80\",\n",
      "  \"Dataofpurchase\": \"03/11/24\",\n",
      "  \"Each Item withs price\": \n",
      "  {\n",
      "    \"Coni di Mais\": \"€4.00\",\n",
      "    \"Bio\": \"€10.00\",\n",
      "    \"Subtot\": \"€6.51\",\n",
      "    \"Totale di cui IVA\": \"€6.51\",\n",
      "    \"Importo Pago\": \"€6.51\",\n",
      "    \"Data\": \"03/11/24\",\n",
      "    \"Tipo di pagamento\": \"EFT-POS\",\n",
      "    \"Forma di pagamento\": \"UcMastercard\",\n",
      "    \"ID\": \"A.ID\",\n",
      "    \"CVM\": \"No CVM\",\n",
      "    \"CVM\": \"No CVM\",\n",
      "    \"Tipo di pagamento\": \"No CVM\",\n",
      "    \"Tipo di pagamento\": \"No CVM\",\n",
      "    \"Tipo di pagamento\": \"No CVM\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(results.split('Extracted Information')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCR_tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
